#!/usr/bin/env python3
"""
æ—¥å¿—å·¥å…·æ¨¡å—
ç»Ÿä¸€ç®¡ç†4DGaussianså’Œç¬¼èŠ‚ç‚¹æ¨¡å‹çš„è®­ç»ƒè®°å½•
"""

import os
import sys
import json
import logging
import datetime
from pathlib import Path
from typing import Dict, Any, Optional
import torch
from pathlib import Path

class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, 
                 log_type: str,  # "4DGaussians" or "cage_model"
                 experiment_name: str,
                 log_dir: str = "logs"):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        
        Args:
            log_type: æ—¥å¿—ç±»å‹ï¼Œ"4DGaussians" æˆ– "cage_model"
            experiment_name: å®éªŒåç§°
            log_dir: æ—¥å¿—æ ¹ç›®å½•
        """
        self.log_type = log_type
        self.experiment_name = experiment_name
        self.log_dir = Path(log_dir)
        
        # åˆ›å»ºæ—¶é—´æˆ³
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
        self.log_subdir = self.log_dir / log_type / experiment_name
        self.log_subdir.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒæ—¥å¿—æ–‡ä»¶
        self.training_log_file = self.log_subdir / f"training_{self.timestamp}.log"
        
        # é…ç½®æ—¥å¿—æ–‡ä»¶
        self.config_file = self.log_subdir / f"config_{self.timestamp}.json"
        
        # æ€§èƒ½ç»Ÿè®¡æ–‡ä»¶
        self.metrics_file = self.log_subdir / f"metrics_{self.timestamp}.json"
        
        # è®¾ç½®Python logging
        self._setup_logger()
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        self.metrics = {
            "start_time": datetime.datetime.now().isoformat(),
            "log_type": log_type,
            "experiment_name": experiment_name,
            "training_stats": {},
            "performance_metrics": {}
        }
        
    def _setup_logger(self):
        """è®¾ç½®Pythonæ—¥å¿—è®°å½•å™¨"""
        # åˆ›å»ºlogger
        self.logger = logging.getLogger(f"{self.log_type}_{self.experiment_name}")
        self.logger.setLevel(logging.INFO)
        
        # æ¸…é™¤å·²æœ‰çš„handlers
        self.logger.handlers.clear()
        
        # æ–‡ä»¶handler
        file_handler = logging.FileHandler(self.training_log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        
        # è®¾ç½®æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # æ·»åŠ handlers
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
    def log_config(self, config: Dict[str, Any]):
        """è®°å½•é…ç½®ä¿¡æ¯"""
        config_data = {
            "timestamp": datetime.datetime.now().isoformat(),
            "log_type": self.log_type,
            "experiment_name": self.experiment_name,
            "config": config
        }
        
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
            
        self.logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {self.config_file}")
        
    def log_training_start(self, **kwargs):
        """è®°å½•è®­ç»ƒå¼€å§‹"""
        start_info = {
            "start_time": datetime.datetime.now().isoformat(),
            **kwargs
        }
        
        self.metrics["training_stats"]["start_info"] = start_info
        self.logger.info(f"ğŸš€ {self.log_type} è®­ç»ƒå¼€å§‹")
        self.logger.info(f"å®éªŒåç§°: {self.experiment_name}")
        
        for key, value in kwargs.items():
            self.logger.info(f"{key}: {value}")
            
    def log_epoch_stats(self, epoch: int, **stats):
        """è®°å½•æ¯ä¸ªepochçš„ç»Ÿè®¡ä¿¡æ¯"""
        epoch_data = {
            "epoch": epoch,
            "timestamp": datetime.datetime.now().isoformat(),
            **stats
        }
        
        if "epochs" not in self.metrics["training_stats"]:
            self.metrics["training_stats"]["epochs"] = []
            
        self.metrics["training_stats"]["epochs"].append(epoch_data)
        
        # è®°å½•åˆ°æ—¥å¿—
        stats_str = ", ".join([f"{k}: {v}" for k, v in stats.items()])
        self.logger.info(f"Epoch {epoch} - {stats_str}")
        
    def log_iteration_stats(self, iteration: int, **stats):
        """è®°å½•æ¯ä¸ªiterationçš„ç»Ÿè®¡ä¿¡æ¯"""
        if "iterations" not in self.metrics["training_stats"]:
            self.metrics["training_stats"]["iterations"] = []
            
        iter_data = {
            "iteration": iteration,
            "timestamp": datetime.datetime.now().isoformat(),
            **stats
        }
        
        self.metrics["training_stats"]["iterations"].append(iter_data)
        
        # æ¯100æ¬¡iterationè®°å½•ä¸€æ¬¡è¯¦ç»†æ—¥å¿—
        if iteration % 100 == 0:
            stats_str = ", ".join([f"{k}: {v}" for k, v in stats.items()])
            self.logger.info(f"Iteration {iteration} - {stats_str}")
            
    def log_training_complete(self, **final_stats):
        """è®°å½•è®­ç»ƒå®Œæˆ"""
        completion_info = {
            "end_time": datetime.datetime.now().isoformat(),
            "total_duration": None,  # å°†åœ¨save_metricsä¸­è®¡ç®—
            **final_stats
        }
        
        self.metrics["training_stats"]["completion_info"] = completion_info
        self.logger.info(f"âœ… {self.log_type} è®­ç»ƒå®Œæˆ")
        
        for key, value in final_stats.items():
            self.logger.info(f"{key}: {value}")
            
    def log_error(self, error_msg: str, exception: Optional[Exception] = None):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        self.logger.error(f"âŒ é”™è¯¯: {error_msg}")
        if exception:
            self.logger.error(f"å¼‚å¸¸è¯¦æƒ…: {str(exception)}")
            
    def _convert_tensors_to_python(self, obj):
        """é€’å½’åœ°å°†PyTorch Tensorå’Œå…¶ä»–ä¸å¯åºåˆ—åŒ–å¯¹è±¡è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹"""
        if isinstance(obj, torch.Tensor):
            if obj.numel() == 1:
                return obj.item()  # æ ‡é‡Tensorè½¬æ¢ä¸ºPythonæ•°å€¼
            else:
                return obj.detach().cpu().tolist()  # å¤šç»´Tensorè½¬æ¢ä¸ºåˆ—è¡¨
        elif isinstance(obj, dict):
            return {k: self._convert_tensors_to_python(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._convert_tensors_to_python(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
            return {k: self._convert_tensors_to_python(v) for k, v in obj.__dict__.items()}
        else:
            # å°è¯•ç¡®ä¿å¯¹è±¡æ˜¯JSONå¯åºåˆ—åŒ–çš„
            try:
                json.dumps(obj)
                return obj
            except (TypeError, ValueError):
                # å¦‚æœä¸èƒ½åºåˆ—åŒ–ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º
                return str(obj)
    
    def save_metrics(self):
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        if "start_info" in self.metrics["training_stats"]:
            start_time = datetime.datetime.fromisoformat(
                self.metrics["training_stats"]["start_info"]["start_time"]
            )
            end_time = datetime.datetime.now()
            duration = str(end_time - start_time)
            
            if "completion_info" in self.metrics["training_stats"]:
                self.metrics["training_stats"]["completion_info"]["total_duration"] = duration
            
        self.metrics["save_time"] = datetime.datetime.now().isoformat()
        
        # è½¬æ¢æ‰€æœ‰Tensorå’Œä¸å¯åºåˆ—åŒ–å¯¹è±¡ä¸ºJSONå…¼å®¹æ ¼å¼
        try:
            serializable_metrics = self._convert_tensors_to_python(self.metrics)
            
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_metrics, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°: {self.metrics_file}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ€§èƒ½æŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")
            # å°è¯•ä¿å­˜åŸºæœ¬ä¿¡æ¯ï¼Œè·³è¿‡å¯èƒ½æœ‰é—®é¢˜çš„æ•°æ®
            basic_metrics = {
                "start_time": self.metrics.get("start_time"),
                "log_type": self.metrics.get("log_type"),
                "experiment_name": self.metrics.get("experiment_name"),
                "save_time": datetime.datetime.now().isoformat(),
                "error": f"éƒ¨åˆ†æ•°æ®æ— æ³•åºåˆ—åŒ–: {str(e)}"
            }
            
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(basic_metrics, f, indent=2, ensure_ascii=False)
                
            self.logger.warning(f"å·²ä¿å­˜åŸºæœ¬æŒ‡æ ‡ä¿¡æ¯åˆ°: {self.metrics_file}")
        
    def get_log_summary(self) -> Dict[str, str]:
        """è·å–æ—¥å¿—æ‘˜è¦ä¿¡æ¯"""
        return {
            "log_type": self.log_type,
            "experiment_name": self.experiment_name,
            "timestamp": self.timestamp,
            "training_log": str(self.training_log_file),
            "config_file": str(self.config_file), 
            "metrics_file": str(self.metrics_file),
            "log_directory": str(self.log_subdir)
        }


def create_training_logger(log_type: str, experiment_name: str) -> TrainingLogger:
    """
    åˆ›å»ºè®­ç»ƒæ—¥å¿—è®°å½•å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        log_type: "4DGaussians" æˆ– "cage_model"
        experiment_name: å®éªŒåç§°
        
    Returns:
        TrainingLoggerå®ä¾‹
    """
    return TrainingLogger(log_type, experiment_name)


def backup_sge_logs(job_id: str, experiment_name: str, log_type: str):
    """
    å¤‡ä»½SGEä½œä¸šæ—¥å¿—æ–‡ä»¶
    
    Args:
        job_id: SGEä½œä¸šID
        experiment_name: å®éªŒåç§°
        log_type: æ—¥å¿—ç±»å‹
    """
    log_dir = Path("logs") / "sge_jobs" / log_type / experiment_name
    log_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å¤‡ä»½.oå’Œ.eæ–‡ä»¶
    for suffix in ['o', 'e']:
        sge_file = f"*.{suffix}{job_id}"
        target_file = log_dir / f"sge_{suffix}_{timestamp}.log"
        
        # ä½¿ç”¨shellå‘½ä»¤å¤åˆ¶æ–‡ä»¶
        import subprocess
        try:
            subprocess.run(
                f"cp {sge_file} {target_file}", 
                shell=True, 
                check=True
            )
            print(f"âœ… SGEæ—¥å¿—å·²å¤‡ä»½: {target_file}")
        except subprocess.CalledProcessError:
            print(f"âš ï¸ æœªæ‰¾åˆ°SGEæ—¥å¿—æ–‡ä»¶: {sge_file}")